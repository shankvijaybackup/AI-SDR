# OpenAI Realtime API Migration Guide

## âœ… What's Been Implemented

### New Files Created:
1. **`realtimeVoiceServer.js`** - WebSocket server that connects Twilio â†” OpenAI Realtime API
2. **`routes/voice-realtime.js`** - Twilio voice webhook for Realtime API calls

### Modified Files:
1. **`server.js`** - Added Realtime API routes and WebSocket server
2. **`routes/initiate-call.js`** - Switched to use Realtime API endpoint

## ğŸ¯ Architecture Change

### Before (High Latency - 2-3 seconds):
```
Twilio Call â†’ STT â†’ Backend â†’ OpenAI Chat API â†’ TTS â†’ Twilio
```

### After (Low Latency - 200-400ms):
```
Twilio Media Streams â†â†’ WebSocket â†â†’ OpenAI Realtime API
```

## ğŸš€ How It Works

1. **Call Initiated**: Twilio calls `/api/twilio/voice-realtime`
2. **WebSocket Connection**: Twilio connects to `/twilio-realtime-voice`
3. **OpenAI Connection**: Backend connects to OpenAI Realtime API
4. **Bidirectional Audio**: 
   - Twilio â†’ OpenAI: User speech (Î¼-law audio)
   - OpenAI â†’ Twilio: AI response (Î¼-law audio)
5. **Real-time Processing**: OpenAI handles STT, LLM, and TTS in one stream

## ğŸ“‹ Setup Steps

### 1. Install Dependencies (if needed)
```bash
npm install ws
```

### 2. Verify Environment Variables
Make sure you have in `.env`:
```bash
OPENAI_API_KEY=sk-...
PUBLIC_BASE_URL=https://your-ngrok-url.ngrok-free.app
```

### 3. Restart Backend
```bash
cd backend
npm run dev
```

You should see:
```
âœ… Backend listening on http://localhost:4000
âœ… MediaStream WebSocket server attached at /twilio-media-stream
âœ… Realtime Voice WebSocket server attached at /twilio-realtime-voice
```

### 4. Test a Call
1. Go to `http://localhost:3000/calling`
2. Select your lead
3. Choose script and voice
4. Click "Start Call"
5. Answer your phone

## ğŸ¤ Expected Behavior

**Latency**: 200-400ms (vs 2-3 seconds before)
**Voice**: Natural, human-like conversation
**Interruptions**: Supported (you can interrupt Alex mid-sentence)
**Transcription**: Real-time, accurate

## ğŸ”§ Key Features

### Voice Activity Detection (VAD)
- Automatically detects when user starts/stops speaking
- No need for manual silence detection
- Handles natural pauses and interruptions

### Streaming Audio
- Audio streams in real-time (no buffering)
- Low latency response
- Natural conversation flow

### Persona Configuration
```javascript
voice: call.voicePersona === "male" ? "alloy" : "shimmer"
```

Available voices:
- **alloy** (male, neutral)
- **echo** (male, confident)
- **shimmer** (female, warm) â† Default female
- **nova** (female, energetic)
- **fable** (male, British)
- **onyx** (male, deep)

## ğŸ› Troubleshooting

### Issue: "OpenAI connection failed"
**Solution**: Check OPENAI_API_KEY is valid and has Realtime API access

### Issue: "No audio from AI"
**Solution**: Verify PUBLIC_BASE_URL is correct ngrok URL (no trailing slash)

### Issue: "Call connects but no response"
**Solution**: Check backend logs for WebSocket connection status

### Issue: "High latency still"
**Solution**: Make sure you're using `/api/twilio/voice-realtime` not `/api/twilio/voice`

## ğŸ“Š Monitoring

Watch backend logs for:
```
[Realtime] New Twilio connection: <id>
[Realtime] Stream started: CallSid=<sid>
[Realtime] Connected to OpenAI for CallSid=<sid>
[Realtime] Session configured
[Realtime] User said: "<transcript>"
[Realtime] AI said: "<response>"
```

## ğŸ”„ Rollback (if needed)

To revert to old system:

1. Edit `routes/initiate-call.js`:
```javascript
url: `${publicBaseUrl}/api/twilio/voice?callId=${callId}...`
```

2. Restart backend

## ğŸ¯ Next Steps

1. **Test the new system** - Make a call and verify low latency
2. **Fine-tune persona** - Adjust instructions in `buildRealtimeInstructions()`
3. **Add interruption handling** - Implement `input_audio_buffer.speech_started` logic
4. **Monitor performance** - Track latency and conversation quality

## ğŸ“ Notes

- OpenAI Realtime API is in beta (model: `gpt-4o-realtime-preview-2024-12-17`)
- Pricing: ~$0.06/minute for audio input, ~$0.24/minute for audio output
- Maximum conversation length: ~30 minutes per session
- Supports multiple languages (English optimized)

## ğŸš€ Performance Comparison

| Metric | Old System | New System |
|--------|-----------|------------|
| Latency | 2-3 seconds | 200-400ms |
| Interruptions | Not supported | Supported |
| Voice Quality | Good | Excellent |
| Natural Flow | Robotic | Human-like |
| Cost per minute | ~$0.05 | ~$0.30 |

---

**Status**: âœ… Ready to test
**Last Updated**: Dec 13, 2025
